{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pedidos de crédito\n",
    "\n",
    "<p>Bancos recebem<em> muitos </em> pedidos de crédito e muitos são rejeitados por vários motivos. Analisar manualmente esses pedidos é exaustivo, muito suscetível a falhas e demorado (e tempo é dinheiro). Felizmente essa tarefa pode ser automatizada com aprendizado de máquina (<i>machine learning</i>) e praticamente todo banco faz isso hoje em dia. Neste notebook veremos a construção de um preditor automático de aprovação de crédito utilizando técnicas de <i>machine learning</i>, assim como bancos reais fazem.</p>\n",
    "\n",
    "\n",
    "<p><img src=\"https://assets.datacamp.com/production/project_558/img/credit_card.jpg\" alt=\"Credit card being held in hand\"></p>\n",
    "\n",
    "<p>Utilizaremos o <a href=\"http://archive.ics.uci.edu/ml/datasets/credit+approval\">Credit Card Approval dataset</a> do repositório de dados \"UCI Machine Learning Repository\". Segue a organização deste notebook:</p>\n",
    "<ul>\n",
    "<li>Primeiro, vamos carregar e visualizar o dataset.</li>\n",
    "<li>Veremos que o dataset é uma mistura tanto de características numéricas e não numéricas, que contém valores de diferentes amplitudes, além de valores faltantes.</li>\n",
    "    \n",
    "<li>Teremos que pré processar o dataset para garantir que o modelo que escolhermos possa fazer boas previsões</li>\n",
    "    \n",
    "<li>Na sequencia faremos uma análise exploratória dos dados</li>\n",
    "<li>Finalmente, contruiremos um modelo de machine learning que seja capaz de prever se o pedido de crédito de um cliente será aprovado ou não.</li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "<p>Primeiro, carregaremos o dataset. Já que os dados são confidenciais, o contribuidor do dataset anonimizou os nomes das características. Trataremos cada coluna como um número. Isso não deverá ser um problema para este projeto.</p>\n",
    "\n",
    "<p> A coluna que queremos prever (o nosso <i>target</i>) é a coluna 15 </p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00202</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00043</td>\n",
       "      <td>560</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>1.50</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00280</td>\n",
       "      <td>824</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00100</td>\n",
       "      <td>3</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>00120</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  0      1      2  3  4  5  6     7  8  9   10 11 12     13   14 15\n",
       "0  b  30.83  0.000  u  g  w  v  1.25  t  t   1  f  g  00202    0  +\n",
       "1  a  58.67  4.460  u  g  q  h  3.04  t  t   6  f  g  00043  560  +\n",
       "2  a  24.50  0.500  u  g  q  h  1.50  t  f   0  f  g  00280  824  +\n",
       "3  b  27.83  1.540  u  g  w  v  3.75  t  t   5  t  g  00100    3  +\n",
       "4  b  20.17  5.625  u  g  w  v  1.71  t  f   0  f  s  00120    0  +"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "cc_apps = pd.read_csv(\"datasets/cc_approvals.data\", header=None)\n",
    "cc_apps.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inspecionando os pedidos\n",
    "\n",
    "<p>Os dados podem parecer confusos a primeira vista. Como já mencionado, as features deste dataset foram anonimizadas para proteger a privacidade dos clientes, mas <a href=\"http://rstudio-pubs-static.s3.amazonaws.com/73039_9946de135c0a49daa7a0a9eda4a67a72.html\">este blog</a> nos dá uma boa idéia de o que as features provavelmente são. Provavelmente temos <code>Sexo</code>, <code>Idade</code>, <code>Débito</code>, <code>Estado civil</code>, <code>Cliente Tipo</code>, <code>Escolaridade</code>, <code>Etinia</code>, <code>Anos empregado</code>, <code>Dívida anterior</code>, <code>Empregado</code>, <code>Score de crédito</code>, <code>Carteira de Habilitação</code>, <code>Cidadania</code>, <code>CEP</code>, <code>Renda</code> e finalmente o <code>Status de Aprovação</code>. Isso nos dá um bom ponto de partida caso precisemos mapear essas features no resultado. </p>\n",
    "\n",
    "<p>O dataset é uma mistura de dados numéricos e categóricos. Isso pode ser corrigido com algum pré-processamento, mas antes disso, vamos aprender mais sobre o dataset para descobrir o que mais precisa ser corrigido.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               2           7          10             14\n",
      "count  690.000000  690.000000  690.00000     690.000000\n",
      "mean     4.758725    2.223406    2.40000    1017.385507\n",
      "std      4.978163    3.346513    4.86294    5210.102598\n",
      "min      0.000000    0.000000    0.00000       0.000000\n",
      "25%      1.000000    0.165000    0.00000       0.000000\n",
      "50%      2.750000    1.000000    0.00000       5.000000\n",
      "75%      7.207500    2.625000    3.00000     395.500000\n",
      "max     28.000000   28.500000   67.00000  100000.000000\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 16 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       690 non-null    object \n",
      " 1   1       690 non-null    object \n",
      " 2   2       690 non-null    float64\n",
      " 3   3       690 non-null    object \n",
      " 4   4       690 non-null    object \n",
      " 5   5       690 non-null    object \n",
      " 6   6       690 non-null    object \n",
      " 7   7       690 non-null    float64\n",
      " 8   8       690 non-null    object \n",
      " 9   9       690 non-null    object \n",
      " 10  10      690 non-null    int64  \n",
      " 11  11      690 non-null    object \n",
      " 12  12      690 non-null    object \n",
      " 13  13      690 non-null    object \n",
      " 14  14      690 non-null    int64  \n",
      " 15  15      690 non-null    object \n",
      "dtypes: float64(2), int64(2), object(12)\n",
      "memory usage: 86.4+ KB\n",
      "None\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     0\n",
       "8     0\n",
       "9     0\n",
       "10    0\n",
       "11    0\n",
       "12    0\n",
       "13    0\n",
       "14    0\n",
       "15    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imprimindo describe() do dataset\n",
    "cc_apps_description = cc_apps.describe()\n",
    "print(cc_apps_description)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Imprimindo info() do dataset\n",
    "cc_apps_info = cc_apps.info()\n",
    "print(cc_apps_info)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "#total de valores nulos\n",
    "\n",
    "cc_apps.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tratando valores faltantes (parte i)\n",
    "\n",
    "<p>Alguns problemas que vão afetar nosso modelo caso não sejam tratados:</p>\n",
    "<ul>\n",
    "<li>Nosso dataset contém valores numéricos e categóricos </li>\n",
    "<li>O data set contém valores de várias amplitures. Algumas características variam entre  0 - 28, algumas entre 2 - 67, e outras tem uma variação de 1017 - 100000. Tirando essas, nós conseguimos dados estatísticas úteis (como <code>média</code>, <code>máximo</code>, e <code>mínimo</code>) sobre as características que tem valores numéricos. </li>\n",
    "\n",
    "<li>Finalmente, o dataset contém valores faltantes, o qual nós trataremos aqui. Apesar de não existirem valores de fato nulos (NaN), existem valores rotulados com '?'.</li>\n",
    "</ul>\n",
    "<p>Primeiro, vamos temporariamente subtituir '?' por NaN.</p>\n",
    "<p>Abaixo podemos observar uma ocorrencia na coluna 0</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0      1       2  3  4   5   6      7  8  9   10 11 12     13   14 15\n",
      "670  b  47.17   5.835  u  g   w   v  5.500  f  f   0  f  g  00465  150  -\n",
      "671  b  25.83  12.835  u  g  cc   v  0.500  f  f   0  f  g  00000    2  -\n",
      "672  a  50.25   0.835  u  g  aa   v  0.500  f  f   0  t  g  00240  117  -\n",
      "673  ?  29.50   2.000  y  p   e   h  2.000  f  f   0  f  g  00256   17  -\n",
      "674  a  37.33   2.500  u  g   i   h  0.210  f  f   0  f  g  00260  246  -\n",
      "675  a  41.58   1.040  u  g  aa   v  0.665  f  f   0  f  g  00240  237  -\n",
      "676  a  30.58  10.665  u  g   q   h  0.085  f  t  12  t  g  00129    3  -\n",
      "677  b  19.42   7.250  u  g   m   v  0.040  f  t   1  f  g  00100    1  -\n",
      "678  a  17.92  10.210  u  g  ff  ff  0.000  f  f   0  f  g  00000   50  -\n",
      "679  a  20.08   1.250  u  g   c   v  0.000  f  f   0  f  g  00000    0  -\n",
      "680  b  19.50   0.290  u  g   k   v  0.290  f  f   0  f  g  00280  364  -\n",
      "681  b  27.83   1.000  y  p   d   h  3.000  f  f   0  f  g  00176  537  -\n",
      "682  b  17.08   3.290  u  g   i   v  0.335  f  f   0  t  g  00140    2  -\n",
      "683  b  36.42   0.750  y  p   d   v  0.585  f  f   0  f  g  00240    3  -\n",
      "684  b  40.58   3.290  u  g   m   v  3.500  f  f   0  t  s  00400    0  -\n",
      "685  b  21.08  10.085  y  p   e   h  1.250  f  f   0  f  g  00260    0  -\n",
      "686  a  22.67   0.750  u  g   c   v  2.000  f  t   2  t  g  00200  394  -\n",
      "687  a  25.25  13.500  y  p  ff  ff  2.000  f  t   1  t  g  00200    1  -\n",
      "688  b  17.92   0.205  u  g  aa   v  0.040  f  f   0  f  g  00280  750  -\n",
      "689  b  35.00   3.375  u  g   c   h  8.290  f  f   0  t  g  00000    0  -\n",
      "\n",
      "##########\n",
      "\n",
      "      0      1       2  3  4   5   6      7  8  9   10 11 12     13   14 15\n",
      "670    b  47.17   5.835  u  g   w   v  5.500  f  f   0  f  g  00465  150  -\n",
      "671    b  25.83  12.835  u  g  cc   v  0.500  f  f   0  f  g  00000    2  -\n",
      "672    a  50.25   0.835  u  g  aa   v  0.500  f  f   0  t  g  00240  117  -\n",
      "673  NaN  29.50   2.000  y  p   e   h  2.000  f  f   0  f  g  00256   17  -\n",
      "674    a  37.33   2.500  u  g   i   h  0.210  f  f   0  f  g  00260  246  -\n",
      "675    a  41.58   1.040  u  g  aa   v  0.665  f  f   0  f  g  00240  237  -\n",
      "676    a  30.58  10.665  u  g   q   h  0.085  f  t  12  t  g  00129    3  -\n",
      "677    b  19.42   7.250  u  g   m   v  0.040  f  t   1  f  g  00100    1  -\n",
      "678    a  17.92  10.210  u  g  ff  ff  0.000  f  f   0  f  g  00000   50  -\n",
      "679    a  20.08   1.250  u  g   c   v  0.000  f  f   0  f  g  00000    0  -\n",
      "680    b  19.50   0.290  u  g   k   v  0.290  f  f   0  f  g  00280  364  -\n",
      "681    b  27.83   1.000  y  p   d   h  3.000  f  f   0  f  g  00176  537  -\n",
      "682    b  17.08   3.290  u  g   i   v  0.335  f  f   0  t  g  00140    2  -\n",
      "683    b  36.42   0.750  y  p   d   v  0.585  f  f   0  f  g  00240    3  -\n",
      "684    b  40.58   3.290  u  g   m   v  3.500  f  f   0  t  s  00400    0  -\n",
      "685    b  21.08  10.085  y  p   e   h  1.250  f  f   0  f  g  00260    0  -\n",
      "686    a  22.67   0.750  u  g   c   v  2.000  f  t   2  t  g  00200  394  -\n",
      "687    a  25.25  13.500  y  p  ff  ff  2.000  f  t   1  t  g  00200    1  -\n",
      "688    b  17.92   0.205  u  g  aa   v  0.040  f  f   0  f  g  00280  750  -\n",
      "689    b  35.00   3.375  u  g   c   h  8.290  f  f   0  t  g  00000    0  -\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Inspecionando valores faltantes \n",
    "print(cc_apps.tail(20))\n",
    "\n",
    "# Verificando novamente...\n",
    "print(\"\\n##########\\n\"),\n",
    "cc_apps = cc_apps.replace(\"?\", np.nan)\n",
    "print(cc_apps.tail(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tratando valores faltantes (parte ii)\n",
    "\n",
    "<p>Substituímos '?' com NaNs. </p>\n",
    "<p>Usaremos a estratégia de imputação da média para os valores faltantes.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     12\n",
       "1     12\n",
       "2      0\n",
       "3      6\n",
       "4      6\n",
       "5      9\n",
       "6      9\n",
       "7      0\n",
       "8      0\n",
       "9      0\n",
       "10     0\n",
       "11     0\n",
       "12     0\n",
       "13    13\n",
       "14     0\n",
       "15     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Impute the missing values with mean imputation\n",
    "cc_apps.fillna(cc_apps.mean(), inplace=True)\n",
    "\n",
    "# Contagem dos valores faltantes\n",
    "cc_apps.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tratando valores faltantes (parte iii)\n",
    "\n",
    "<p>Tratamos os valores falantes com sucesso, porém somente nas colunas numéricas. Ainda existem valores faltantes nas colunas 0, 1, 3, 4, 5, 6 e 13. Todas essas colunas contém dados não numéricos. Portanto a imputação da média não funcionaria aqui. </p>\n",
    "<p>Uma <a href=\"https://www.datacamp.com/community/tutorials/categorical-data\">boa prática</a> é imputar com o valor mais frequente, como faremos em seguida.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     0\n",
       "8     0\n",
       "9     0\n",
       "10    0\n",
       "11    0\n",
       "12    0\n",
       "13    0\n",
       "14    0\n",
       "15    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in cc_apps.columns:\n",
    "    if cc_apps[col].dtype == 'object':\n",
    "        cc_apps = cc_apps.fillna(cc_apps[col].value_counts().index[0])\n",
    "\n",
    "# Contagem dos valores faltantes\n",
    "cc_apps.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Pré-processamento dos dados (parte i)\n",
    "\n",
    "<p>Resolvemos os valores faltantes.</p>\n",
    "<p>Ainda existem outras etapas de pré-processamento que devemos executar antes de partirmos para o modelo. Dividiremos essas etapas em três partes: </p>\n",
    "<ol>\n",
    "<li>Converter dados não numéricos para numéricos </li>\n",
    "<li>Dividir os dados em treino e teste</li>\n",
    "<li>Escalonar os dados para um intervalo uniforme</li>\n",
    "</ol>\n",
    "<p>Primeiro, vamos converter todos valores categóricos em numéricos. Nós faremos isso não somente por resultar em uma computação mais rápida mas também porque muitos modelos de <i>machine learning</i> (como o XGBoost) (e especialemnte aqueles que foram desenvolvidos usando scikit-learn) requerem que os dados sejam numéricos. Faremos isso usando uma técnica chamada <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\">label encoding</a>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "for col in cc_apps.columns.values:\n",
    "    if cc_apps[col].dtype =='object':\n",
    "        cc_apps[col] = le.fit_transform(cc_apps[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>328</td>\n",
       "      <td>4.460</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>3.04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>560</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>0.500</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>824</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1.540</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>5.625</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1      2   3   4   5   6     7   8   9   10  11  12  13   14  15\n",
       "0   1  156  0.000   2   1  13   8  1.25   1   1   1   0   0  68    0   0\n",
       "1   0  328  4.460   2   1  11   4  3.04   1   1   6   0   0  11  560   0\n",
       "2   0   89  0.500   2   1  11   4  1.50   1   0   0   0   0  96  824   0\n",
       "3   1  125  1.540   2   1  13   8  3.75   1   1   5   1   0  31    3   0\n",
       "4   1   43  5.625   2   1  13   8  1.71   1   0   0   0   2  37    0   0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_apps.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>Sexo</code>, <code>Idade</code>, <code>Débito</code>, <code>Estado civil</code>, <code>Cliente Tipo</code>, <code>Escolaridade</code>, <code>Etinia</code>, <code>Anos empregado</code>, <code>Dívida anterior</code>, <code>Empregado</code>, <code>Score de crédito</code>, <code>Carteira de Habilitação</code>, <code>Cidadania</code>, <code>CEP</code>, <code>Renda</code> e finalmente o <code>Status de Aprovação</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Dividindo os dados em sets de treino e teste\n",
    "\n",
    "<p>Agora vamos dividir os dados em treino e teste. Normalmente, nenhuma informação dos dados de teste deve ser usada para escalonar os dados de treino ou usada para direcionar a fase de treino de uma modelo de machine learning. Portanto, primeiro diviremos os dados e então aplicaremos o escalonamento.\n",
    "</p>\n",
    "<p>Além disso, características like <code>Carteira de Habilitação</code> e <code>CEP</code> não são tão importantes quanto outras carterísticas para prever aprovação de crédito. Nõs devemos remove-las para fornecer ao modelo o melhor conjunto de características. Na literatura sobre Ciência de Dados, isso é comumente chamado de <em>feature selection</em>. </p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Removendo as características 11 e 13 e convertendo o DataFrame em um array NumPy\n",
    "cc_apps = cc_apps.drop([11, 13], axis=1)\n",
    "\n",
    "cc_apps = cc_apps.values\n",
    "\n",
    "# Separandoa s características e labels em diferentes variáveis\n",
    "X,y = cc_apps[:,0:-1] , cc_apps[:,-1]\n",
    "\n",
    "# Dividindo entre treino e teste, sendo teste 33% dos dados.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Pré-processamento dos dados (parte ii)\n",
    "\n",
    "<p> Só nos restou mais uma etapa de pré-processamento que é escalonamento dos dados antes que treinemos o modelo.</p>\n",
    "\n",
    "<p>Agora, vamos tentar entender o que esses dados escalonados representam no mundo real. Vamos usar <code>Score de crédito</code> como exemplo. O score de crédito é dado com base no histórico de crédito do cliente. Quanto maior esse número, mais financeiramente confiável a pessoa é considerada ser. Logo, um <code>Score de crédito</code> de 1 é o maior uma vez que estamos escalonando os valores entre 0 e 1 </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "rescaledX_train = scaler.fit_transform(X_train)\n",
    "rescaledX_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Treinando os dados em um modelo de regressão logística.\n",
    "\n",
    "<p>Essencialmente, prever se um pedido de crédito será aprovado ou não é uma tarefa de <a href=\"https://en.wikipedia.org/wiki/Statistical_classification\">classificação</a>. <a href=\"http://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.names\">De acordo com a UCI</a>, nosso dataset contém mais instâncias que correspondem a \"Negado\" (\"Denied\") do que \"Aprovado\" (\"Approved\"). Especificamente, de 690 instancias, existem 383 (55.5%) pedidos que foram negados e 307 (44.5%) pedidos foram aprovados. </p>\n",
    "\n",
    "<p>Isso nos dá um benchmark. Um bom modelo de machine learning deve ser capaz de prever corretamente o status dos clientes de acordo com essas estatísticas.</p>\n",
    "\n",
    "<p>Quais modelo devemos selecionar? A pergunta deve ser: <em>quais características que afetam a decisão de aprovação de crédito são correlacionadas uma com a outra?</em> Apesar de podermos medir a correlação, isso está fora do escopo deste notebook, portanto confiaremos que elas estão de fato correlacionadas por enquanto. Por causa dessa correlação, aproveitaremos do fato de que modelos lineares performam bem nesses casos. Vamos começar com um modelo de Regressão Logística.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(rescaledX_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Fazendo previsões e avaliando performance\n",
    "<p>Mas quão bom é o modelo? </p>\n",
    "<p>Agora vamos avaliar o modelo de classificação no conjunto de teste quanto a sua <a href=\"https://developers.google.com/machine-learning/crash-course/classification/accuracy\">Acurácia (classification accuracy)</a>. Após realizarmos a previsão, também olharemos para o seu <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\">f1-score</a> Também olharemos para a sua  <a href=\"http://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/\">matriz de confusão</a>. Também é importante vermos se nosso modelo é capaz de prever o status de aprovação  como negados e que de fato foram originalmente negados. Se nosso modelo não estiver perfomando bem neste aspecto, ele pode acabar aprovando pedidos que deveriam ter sido negados. A matriz de confusão nos ajudará a avaliar a performance do modelo nesses aspectos. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do classificador:  0.8421052631578947\n",
      "F1-Score:  0.8448275862068965\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84       103\n",
      "         1.0       0.92      0.78      0.84       125\n",
      "\n",
      "    accuracy                           0.84       228\n",
      "   macro avg       0.85      0.85      0.84       228\n",
      "weighted avg       0.85      0.84      0.84       228\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Acurácia do classificador: \", logreg.score(rescaledX_test, y_test))\n",
    "\n",
    "y_pred = logreg.predict(rescaledX_test)\n",
    "\n",
    "print(\"F1-Score: \", f1_score(y_test, y_pred))\n",
    "\n",
    "confusion_matrix(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Grid Search - melhorando a performance do modelo\n",
    "\n",
    "<p>O modelo foi capaz de prever com uma acurácia de 84%. Mas acurácia não é uma medida confiável de desempenho.</p>\n",
    "\n",
    "<p>Na matriz de confusão, o primeiro elemento da primeira linha representa os Verdadeiros Positivos (Pode parecer confuso, mas aqui, \"positivo\" significa que o resultado é 1, ou seja que o pedido de crédito foi <b>negado</b>), sendo o numero de previsões corretas em que o modelo previu como pedido <b>negado</b>. E o segundo elemento da segunda linha são os Verdadeiros Negativos, ou seja, o numero de previsões corretas para pedido <b>aprovado</b>.</p>\n",
    "\n",
    "\n",
    "<p>Vejamos se conseguimos melhorar esses resultados. Podemos realizar um <a href=\"https://machinelearningmastery.com/how-to-tune-algorithm-parameters-with-scikit-learn/\">grid search</a> nos hiperparâmetros do modelo para melhorar a habilidade de prever aprovações de pedidos de crédito.</p>\n",
    "<p><a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\">A implementação do scikit-learn para regressões logísticas</a> consiste de diferentes hiperparâmetros, mas vamos buscar a melhor configuração para os seguintes:</p>\n",
    "<ul>\n",
    "<li>tol</li>\n",
    "<li>max_iter</li>\n",
    "<li>C</li> \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define os valores a serem testados em tol e max_iter\n",
    "tol = [0.01,0.001,0.0001, 1, 10, 100]\n",
    "max_iter = [100,150,200]\n",
    "C = np.linspace(1, 100 , 5)\n",
    "\n",
    "# Cria um dicionario com os valores a serem testados\n",
    "param_grid = {\"tol\" : tol, \"max_iter\" : max_iter, \"C\": C}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Sintonia de hiperparâmetros e validação cruzada\n",
    "\n",
    "<p> Definimos o <em>grid</em> de hiperparâmetros e os convertemos para um único dicionário o qual <code>GridSearchCV()</code> receberá como um dos seus parâmetros. Agora, iniciaremos o <em>grid search</em> para ver quais valores performam melhor.</p>\n",
    "\n",
    "<p>Criaremos uma instancia de <code>GridSearchCV()</code> com o nosso modelo <code>logreg</code> com todos os nossos dados. \n",
    "Ao invés de passar treino e teste separadamente, vamos oferecer todo o<code>X</code> (versão escalonada) e o <code>y</code>. Também vamos instruir o <code>GridSearchCV()</code> para realizar <a href=\"https://www.dataschool.io/machine-learning-with-scikit-learn/\">cross-validation (validação cruzada)</a> em dez <em>folds</em> ou dobras.</p>\n",
    "\n",
    "<p>Terminaremos este notebook armazenando o melhor score obtido, assim como os melhores parâmetros.</p>\n",
    "<p>Na construção deste classificador, abordamos algumas das etapas mais conhecidade de pré-processamento como <strong>escalonamento</strong>, <strong>label encoding</strong>, e <strong>imputação de valores faltantes</strong>. Terminamos com um modelo de  <strong> machine learning </strong> para prever se um pedido de crédito será aprovado ou não com base nos dados do cliente.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scorer:  make_scorer(f1_score, average=binary)\n",
      "Melhor score  0.829388 usando {'C': 1.0, 'max_iter': 100, 'tol': 10}\n"
     ]
    }
   ],
   "source": [
    "grid_model = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=10, scoring='f1')\n",
    "\n",
    "rescaledX = scaler.fit_transform(X)\n",
    "grid_model_result = grid_model.fit(rescaledX, y)\n",
    "\n",
    "scorer = grid_model_result.scorer_\n",
    "print('Scorer: ', scorer)\n",
    "best_score, best_params= grid_model_result.best_score_, grid_model_result.best_params_\n",
    "print(\"Melhor score  %f usando %s\" % (best_score, best_params))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
